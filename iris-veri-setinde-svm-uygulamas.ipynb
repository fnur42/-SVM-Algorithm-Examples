{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":420,"sourceType":"datasetVersion","datasetId":19}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Verilerin Önizlemesi\n- Her biri 4 özelliğe (çanak yaprağı uzunluğu, çanak yaprağı genişliği, taç yaprağı uzunluğu, taç yaprağı genişliği) sahip 150 gözlem vardır.\n- Boş değer yoktur, dolayısıyla bu konuda endişelenmemize gerek yok.\n- Her türe (setosa, versicolor, virginica) ait 50'şer gözlem bulunmaktadır.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/iris/Iris.csv')\ndf = df.drop(['Id'],axis=1)\ntarget = df['Species']\ns = set()\nfor val in target:\n    s.add(val)\ns = list(s)\nrows = list(range(100,150))\ndf = df.drop(df.index[rows])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-29T16:04:49.608379Z","iopub.execute_input":"2023-11-29T16:04:49.609350Z","iopub.status.idle":"2023-11-29T16:04:49.619596Z","shell.execute_reply.started":"2023-11-29T16:04:49.609313Z","shell.execute_reply":"2023-11-29T16:04:49.618189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Iris veri setinde üç sınıf bulunduğundan sınıflardan birini kaldıracağız. Bu bizi ikili sınıf sınıflandırma problemiyle karşı karşıya bırakıyor.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx = df['SepalLengthCm']\ny = df['PetalLengthCm']\n\nsetosa_x = x[:50]\nsetosa_y = y[:50]\n\nversicolor_x = x[50:]\nversicolor_y = y[50:]\n\nplt.figure(figsize=(8,6))\nplt.scatter(setosa_x,setosa_y,marker='+',color='green')\nplt.scatter(versicolor_x,versicolor_y,marker='_',color='red')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:04:55.060220Z","iopub.execute_input":"2023-11-29T16:04:55.061022Z","iopub.status.idle":"2023-11-29T16:04:55.312488Z","shell.execute_reply.started":"2023-11-29T16:04:55.060981Z","shell.execute_reply":"2023-11-29T16:04:55.311389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ayrıca kullanabileceğimiz dört özellik var. Yalnızca iki özelliği kullanacağız, yani Sepal uzunluğu ve Petal uzunluğu. Bu iki özelliği alıyoruz ve görselleştirmek için bunları çiziyoruz. Yukarıdaki grafikten veri noktalarını ayırmak için doğrusal bir çizginin kullanılabileceği sonucunu çıkarabilirsiniz.","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n## Drop rest of the features and extract the target values\ndf = df.drop(['SepalWidthCm','PetalWidthCm'],axis=1)\nY = []\ntarget = df['Species']\nfor val in target:\n    if(val == 'Iris-setosa'):\n        Y.append(-1)\n    else:\n        Y.append(1)\ndf = df.drop(['Species'],axis=1)\nX = df.values.tolist()\n## Shuffle and split the data into training and test set\nX, Y = shuffle(X,Y)\nx_train = []\ny_train = []\nx_test = []\ny_test = []\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.9)\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_test = np.array(x_test)\ny_test = np.array(y_test)\n\ny_train = y_train.reshape(90,1)\ny_test = y_test.reshape(10,1)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:07:55.955358Z","iopub.execute_input":"2023-11-29T16:07:55.955900Z","iopub.status.idle":"2023-11-29T16:07:56.098394Z","shell.execute_reply.started":"2023-11-29T16:07:55.955862Z","shell.execute_reply":"2023-11-29T16:07:56.097218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gerekli özellikleri çıkarıp eğitim ve test verilerine bölüyoruz. Verilerin %90'ı eğitim için, geri kalan %10'u ise test için kullanılır. Şimdi Numpy kütüphanesini kullanarak SVM modelimizi oluşturalım.","metadata":{}},{"cell_type":"code","source":"## Support Vector Machine \nimport numpy as np\n\ntrain_f1 = x_train[:,0]\ntrain_f2 = x_train[:,1]\n\ntrain_f1 = train_f1.reshape(90,1)\ntrain_f2 = train_f2.reshape(90,1)\n\nw1 = np.zeros((90,1))\nw2 = np.zeros((90,1))\n\nepochs = 1\nalpha = 0.0001\n\nwhile(epochs < 10000):\n    y = w1 * train_f1 + w2 * train_f2\n    prod = y * y_train\n    print(epochs)\n    count = 0\n    for val in prod:\n        if(val >= 1):\n            cost = 0\n            w1 = w1 - alpha * (2 * 1/epochs * w1)\n            w2 = w2 - alpha * (2 * 1/epochs * w2)\n            \n        else:\n            cost = 1 - val \n            w1 = w1 + alpha * (train_f1[count] * y_train[count] - 2 * 1/epochs * w1)\n            w2 = w2 + alpha * (train_f2[count] * y_train[count] - 2 * 1/epochs * w2)\n        count += 1\n    epochs += 1","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:07:59.046840Z","iopub.execute_input":"2023-11-29T16:07:59.047249Z","iopub.status.idle":"2023-11-29T16:08:07.543180Z","shell.execute_reply.started":"2023-11-29T16:07:59.047217Z","shell.execute_reply":"2023-11-29T16:08:07.541878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"α(0,0001) öğrenme hızıdır ve düzenleme parametresi λ, 1/dönem olarak ayarlanır. Bu nedenle, düzenlileştirme değeri arttıkça çağ sayısı azalır.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n## Clip the weights \nindex = list(range(10,90))\nw1 = np.delete(w1,index)\nw2 = np.delete(w2,index)\n\nw1 = w1.reshape(10,1)\nw2 = w2.reshape(10,1)\n## Extract the test data features \ntest_f1 = x_test[:,0]\ntest_f2 = x_test[:,1]\n\ntest_f1 = test_f1.reshape(10,1)\ntest_f2 = test_f2.reshape(10,1)\n## Predict\ny_pred = w1 * test_f1 + w2 * test_f2\npredictions = []\nfor val in y_pred:\n    if(val > 1):\n        predictions.append(1)\n    else:\n        predictions.append(-1)\n\nprint(accuracy_score(y_test,predictions))","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:08:22.882144Z","iopub.execute_input":"2023-11-29T16:08:22.882600Z","iopub.status.idle":"2023-11-29T16:08:22.893236Z","shell.execute_reply.started":"2023-11-29T16:08:22.882562Z","shell.execute_reply":"2023-11-29T16:08:22.891855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test verileri yalnızca 10 veri noktası içerdiğinden artık ağırlıkları kırpıyoruz. Özellikleri test verilerinden çıkarıyoruz ve değerleri tahmin ediyoruz. \nTahminleri elde edip gerçek değerlerle karşılaştırıp modelimizin doğruluğunu yazdırıyoruz.","metadata":{}},{"cell_type":"markdown","source":"SVM algoritmasını uygulamanın başka bir basit yolu daha var. SVM modelini uygulamak için Scikit öğrenme kütüphanesini kullanabilir ve sadece ilgili fonksiyonları çağırabiliriz. Kod satırı sayısı önemli ölçüde çok az satır azaltır.","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\nclf = SVC(kernel='linear')\nclf.fit(x_train,y_train)\ny_pred = clf.predict(x_test)\nprint(accuracy_score(y_test,y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:08:25.663577Z","iopub.execute_input":"2023-11-29T16:08:25.664019Z","iopub.status.idle":"2023-11-29T16:08:25.765348Z","shell.execute_reply.started":"2023-11-29T16:08:25.663985Z","shell.execute_reply":"2023-11-29T16:08:25.764193Z"},"trusted":true},"execution_count":null,"outputs":[]}]}